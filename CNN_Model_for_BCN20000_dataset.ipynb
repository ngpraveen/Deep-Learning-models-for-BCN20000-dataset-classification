{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b1c6ccb-3461-471a-8f47-a79aaaff346d",
   "metadata": {},
   "source": [
    "## A Custom Convolutional Neural Network (CNN) Model to Classify BCN20000 Dataset\n",
    "\n",
    "BCN20000 is a dataset consisting of dermoscopic images collated at the Hospital ClÃ­nic in Barcelona, Spain between 2010 and 2016. The dataset consists of eight key diagnostic categories in demoscopy such as melanoma and basal cell carcinoma. The dataset can be found [hereðŸ¡µ](https://figshare.com/articles/journal_contribution/BCN20000_Dermoscopic_Lesions_in_the_Wild/24140028/1) and the details are described in a peer reviewed article [hereðŸ¡µ](https://www.nature.com/articles/s41597-024-03387-w).\n",
    "\n",
    "In this notebook, a custom deep lerning (CNN) model is constructed using PyTorch with the aim of classifying the images to the diagnostic category. The training data is augmented using random horizontal flip, random rotation and adjusting brightness. Data is also resized, cropped and normalized. \n",
    "\n",
    "**Dependencies:** \n",
    "\n",
    "The notebook assumes\n",
    "* The training set images from BCN20000 are in a directory `train` within the root directory.\n",
    "* The metadata file, `bcn_20k_train.csv` is in the root directory\n",
    "* The BCN20000 test dataset is not labelled, so the train dataset is split for validation.\n",
    "\n",
    "**Todo:**\n",
    "* Run more epochs to see whether model performance improves further.\n",
    "* Analyzing model predictions (confusion matrix etc.)\n",
    "* Handling imbalanced data. Test weighted sampling or a different loss function.\n",
    "* Make the code more robust by introducing error handling (e.g. while loading input images) and adding logs.\n",
    "* Compare other neural network models (EfficientNet, [ResNetðŸ¡µ](https://github.com/ngpraveen/Deep-Learning-models-for-BCN20000-dataset-classification/blob/main/ResNet18-Model_for_BCN20000_dataset.ipynb), ...)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b45feef-ad71-48d6-a498-18d5c62b1431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch import optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b570bfeb-221d-4cf8-a68a-f894065e0b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/mnt/c/Users/prave/data/BCN20K_figshare/'\n",
    "\n",
    "target_map = {'NV': 0, 'MEL': 1, 'BCC': 2, 'BKL': 3, 'AK': 4, 'SCC': 5, 'DF': 6, 'VASC': 7}\n",
    "\n",
    "# decides whether to use weighted samples for imbalanced data\n",
    "use_weighted_samples = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51474c3-985e-4438-913b-b7845f4589d3",
   "metadata": {},
   "source": [
    "### 1. Inspecting Metadata File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "978cf33c-142f-4d87-8929-23b5d5445b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(root_dir, \"bcn_20k_train.csv\"))\n",
    "# df_test = pd.read_csv(os.path.join(root_dir, \"bcn_20k_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fbc4c56-db1b-47d2-a319-93e1f41ebca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bcn_filename</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>capture_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCN_0000000001.jpg</td>\n",
       "      <td>55.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>MEL</td>\n",
       "      <td>BCN_0003884</td>\n",
       "      <td>2012-05-16</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCN_0000000003.jpg</td>\n",
       "      <td>50.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>MEL</td>\n",
       "      <td>BCN_0000019</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>female</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCN_0000000004.jpg</td>\n",
       "      <td>85.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>SCC</td>\n",
       "      <td>BCN_0003499</td>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCN_0000000006.jpg</td>\n",
       "      <td>60.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>NV</td>\n",
       "      <td>BCN_0003316</td>\n",
       "      <td>2015-06-16</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCN_0000000010.jpg</td>\n",
       "      <td>30.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCN_0004874</td>\n",
       "      <td>2014-02-18</td>\n",
       "      <td>female</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bcn_filename  age_approx anatom_site_general diagnosis    lesion_id  \\\n",
       "0  BCN_0000000001.jpg        55.0      anterior torso       MEL  BCN_0003884   \n",
       "1  BCN_0000000003.jpg        50.0      anterior torso       MEL  BCN_0000019   \n",
       "2  BCN_0000000004.jpg        85.0           head/neck       SCC  BCN_0003499   \n",
       "3  BCN_0000000006.jpg        60.0      anterior torso        NV  BCN_0003316   \n",
       "4  BCN_0000000010.jpg        30.0      anterior torso       BCC  BCN_0004874   \n",
       "\n",
       "  capture_date     sex  split  \n",
       "0   2012-05-16    male  train  \n",
       "1   2015-07-09  female  train  \n",
       "2   2015-11-23    male  train  \n",
       "3   2015-06-16    male  train  \n",
       "4   2014-02-18  female  train  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc4ce32-ac96-4788-a40e-353ea5356ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['target'] = df_train['diagnosis'].map(target_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "868679b4-a823-4a17-8267-a02578aba66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bcn_filename</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>capture_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCN_0000000001.jpg</td>\n",
       "      <td>55.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>MEL</td>\n",
       "      <td>BCN_0003884</td>\n",
       "      <td>2012-05-16</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCN_0000000003.jpg</td>\n",
       "      <td>50.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>MEL</td>\n",
       "      <td>BCN_0000019</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>female</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCN_0000000004.jpg</td>\n",
       "      <td>85.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>SCC</td>\n",
       "      <td>BCN_0003499</td>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCN_0000000006.jpg</td>\n",
       "      <td>60.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>NV</td>\n",
       "      <td>BCN_0003316</td>\n",
       "      <td>2015-06-16</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCN_0000000010.jpg</td>\n",
       "      <td>30.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCN_0004874</td>\n",
       "      <td>2014-02-18</td>\n",
       "      <td>female</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bcn_filename  age_approx anatom_site_general diagnosis    lesion_id  \\\n",
       "0  BCN_0000000001.jpg        55.0      anterior torso       MEL  BCN_0003884   \n",
       "1  BCN_0000000003.jpg        50.0      anterior torso       MEL  BCN_0000019   \n",
       "2  BCN_0000000004.jpg        85.0           head/neck       SCC  BCN_0003499   \n",
       "3  BCN_0000000006.jpg        60.0      anterior torso        NV  BCN_0003316   \n",
       "4  BCN_0000000010.jpg        30.0      anterior torso       BCC  BCN_0004874   \n",
       "\n",
       "  capture_date     sex  split  target  \n",
       "0   2012-05-16    male  train       1  \n",
       "1   2015-07-09  female  train       1  \n",
       "2   2015-11-23    male  train       5  \n",
       "3   2015-06-16    male  train       0  \n",
       "4   2014-02-18  female  train       2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076340bb-07ff-4eb1-95c1-7f7abd01a9d3",
   "metadata": {},
   "source": [
    "### 2. Create a Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36ae4fc2-9cb1-40f4-9aa2-09af5d46c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCNDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Creates a custom dataset class that inherits from PyTorch's Dataset class.\n",
    "    The metadata content (bcn_20k_train.csv) is added to an attribute `metadata`.\n",
    "    The output class is defined in the column `diagnosis` which is coded to 0, 1, 2, ...\n",
    "    as defined in `target_map`.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): The root directory where the dataset is stored. \n",
    "        transform (callable, optional): Optional transform to be applied to the input data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir: str, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_dir = os.path.join(root_dir, \"train\")\n",
    "        self.transform = transform\n",
    "        self.metadata = self.load_metadata()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx:int):\n",
    "        image, label = self.retrieve_image(idx)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)        \n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "    def load_metadata(self):\n",
    "        metadata = pd.read_csv(\n",
    "            os.path.join(self.root_dir, \"bcn_20k_train.csv\")\n",
    "        )\n",
    "        \n",
    "        target_map = {'NV': 0, 'MEL': 1, 'BCC': 2, 'BKL': 3, 'AK': 4, 'SCC': 5, 'DF': 6, 'VASC': 7}\n",
    "        metadata['target'] = metadata['diagnosis'].map(target_map)\n",
    "        return metadata\n",
    "    \n",
    "\n",
    "    def retrieve_image(self, idx: int):\n",
    "        image_name = self.metadata[\"bcn_filename\"].iloc[idx]\n",
    "        image_path = os.path.join(self.image_dir, image_name) \n",
    "        label = self.metadata[\"target\"].iloc[idx]\n",
    "        with Image.open(image_path) as img:\n",
    "            image = img.convert(\"RGB\")\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3410dabb-7886-4f23-b9af-65094012bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_row = BCNDataset(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c49ac186-dfbd-43a4-a027-093c8b4c944f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bcn_filename</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>capture_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCN_0000000001.jpg</td>\n",
       "      <td>55.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>MEL</td>\n",
       "      <td>BCN_0003884</td>\n",
       "      <td>2012-05-16</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCN_0000000003.jpg</td>\n",
       "      <td>50.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>MEL</td>\n",
       "      <td>BCN_0000019</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>female</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCN_0000000004.jpg</td>\n",
       "      <td>85.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>SCC</td>\n",
       "      <td>BCN_0003499</td>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCN_0000000006.jpg</td>\n",
       "      <td>60.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>NV</td>\n",
       "      <td>BCN_0003316</td>\n",
       "      <td>2015-06-16</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCN_0000000010.jpg</td>\n",
       "      <td>30.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCN_0004874</td>\n",
       "      <td>2014-02-18</td>\n",
       "      <td>female</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12408</th>\n",
       "      <td>BCN_0000020348.jpg</td>\n",
       "      <td>85.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCN_0003925</td>\n",
       "      <td>2013-03-05</td>\n",
       "      <td>female</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12409</th>\n",
       "      <td>BCN_0000020349.jpg</td>\n",
       "      <td>65.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>BKL</td>\n",
       "      <td>BCN_0001819</td>\n",
       "      <td>2016-05-05</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12410</th>\n",
       "      <td>BCN_0000020350.jpg</td>\n",
       "      <td>70.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>MEL</td>\n",
       "      <td>BCN_0001085</td>\n",
       "      <td>2015-01-29</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12411</th>\n",
       "      <td>BCN_0000020352.jpg</td>\n",
       "      <td>55.0</td>\n",
       "      <td>palms/soles</td>\n",
       "      <td>NV</td>\n",
       "      <td>BCN_0002083</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>female</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12412</th>\n",
       "      <td>BCN_0000020355.jpg</td>\n",
       "      <td>50.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>BKL</td>\n",
       "      <td>BCN_0001079</td>\n",
       "      <td>2015-06-25</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12413 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             bcn_filename  age_approx anatom_site_general diagnosis  \\\n",
       "0      BCN_0000000001.jpg        55.0      anterior torso       MEL   \n",
       "1      BCN_0000000003.jpg        50.0      anterior torso       MEL   \n",
       "2      BCN_0000000004.jpg        85.0           head/neck       SCC   \n",
       "3      BCN_0000000006.jpg        60.0      anterior torso        NV   \n",
       "4      BCN_0000000010.jpg        30.0      anterior torso       BCC   \n",
       "...                   ...         ...                 ...       ...   \n",
       "12408  BCN_0000020348.jpg        85.0           head/neck       BCC   \n",
       "12409  BCN_0000020349.jpg        65.0      anterior torso       BKL   \n",
       "12410  BCN_0000020350.jpg        70.0     lower extremity       MEL   \n",
       "12411  BCN_0000020352.jpg        55.0         palms/soles        NV   \n",
       "12412  BCN_0000020355.jpg        50.0     upper extremity       BKL   \n",
       "\n",
       "         lesion_id capture_date     sex  split  target  \n",
       "0      BCN_0003884   2012-05-16    male  train       1  \n",
       "1      BCN_0000019   2015-07-09  female  train       1  \n",
       "2      BCN_0003499   2015-11-23    male  train       5  \n",
       "3      BCN_0003316   2015-06-16    male  train       0  \n",
       "4      BCN_0004874   2014-02-18  female  train       2  \n",
       "...            ...          ...     ...    ...     ...  \n",
       "12408  BCN_0003925   2013-03-05  female  train       2  \n",
       "12409  BCN_0001819   2016-05-05    male  train       3  \n",
       "12410  BCN_0001085   2015-01-29    male  train       1  \n",
       "12411  BCN_0002083   2016-05-08  female  train       0  \n",
       "12412  BCN_0001079   2015-06-25    male  train       3  \n",
       "\n",
       "[12413 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_row.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b11089c-7b55-458e-a95b-36bc0bf1d305",
   "metadata": {},
   "source": [
    "### Split Dataset and Create a Dataset Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faa39f26-b97b-496a-b8fb-a66b55e0108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, val_fraction=0.15, test_fraction=0.15):\n",
    "    \"\"\"\n",
    "    Randomly split dataset into train, validation and test datasets.\n",
    "    By default, splits in to 70%, 15% and 15%. \n",
    "\n",
    "    Args:\n",
    "        dataset: The dataset object which is split into train, validation and test datasets.\n",
    "        val_fraction (float, optional): Fraction of the dataset to be included in the validation set.\n",
    "        test_fraction (float, optional): Fraction of the dataset to be included in the test set.  \n",
    "    \"\"\"\n",
    "    \n",
    "    total_size = len(dataset)\n",
    "    val_size = int(total_size * val_fraction)\n",
    "    test_size = int(total_size * test_fraction)\n",
    "    train_size = total_size - val_size - test_size\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, \n",
    "                                                            [train_size, val_size, test_size])\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed3d7e41-9da4-4eef-a2c0-2a92b6d82f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8691, 1861, 1861)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset1, val_dataset1, test_dataset1 = split_dataset(dataset_row)\n",
    "len(train_dataset1), len(val_dataset1), len(test_dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de099590-ee15-4606-8a32-d0372dabcbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubsetWithTransform(Dataset):\n",
    "    \"\"\"\n",
    "    Creates a subset class from BCNDataset objects. \n",
    "    Helps with applying different transforms to the train, validation \n",
    "    and test datasets. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, subset, transform=None):\n",
    "        print(subset)\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.subset[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbcca837-40ac-487d-99f3-10dea5be30a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define different transforms for train and validation+test sets. \n",
    "# Train dataset is augmented with horizontal flip, random rotation etc. \n",
    "# But validation and test sets are not augmented. \n",
    "mean, std = [0.6125, 0.5277, 0.5061], [0.4241, 0.3242, 0.3054]\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2),\n",
    "    transforms.Resize((256, 256)),  # Resize images to 256x256 pixels\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# for validation and test sets.\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize images to 256x256 pixels\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ff3ed5d-8e8a-4523-9be2-417c7bfc352e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.Subset object at 0x7f359976b3a0>\n",
      "<torch.utils.data.dataset.Subset object at 0x7f359976ab60>\n",
      "<torch.utils.data.dataset.Subset object at 0x7f359976a980>\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SubsetWithTransform(train_dataset1, transform=train_transform)\n",
    "val_dataset = SubsetWithTransform(val_dataset1, transform=val_transform)\n",
    "test_dataset = SubsetWithTransform(test_dataset1, transform=val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aaf898-bfe6-4c2f-bdca-8cb4f7f9e19f",
   "metadata": {},
   "source": [
    "### Create a Custom Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cba9de61-d346-4397-87d2-c69bc8b696db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a custom CNN \n",
    "class BCN20DNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A convolutional neural network (CNN) model.\n",
    "\n",
    "    The architecture consists of three convolutional blocks followed by \n",
    "    two fully connected layers. \n",
    "\n",
    "    Args:\n",
    "        num_classes (int): Number of classes in the training dataset. \n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super(BCN20DNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten4 = nn.Flatten()\n",
    "\n",
    "        self.fc5a = nn.Linear(128 * 28 * 28, 512)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "        self.fc5b = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # conv block 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # conv block 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.flatten4(x)\n",
    "\n",
    "        # fully connected layers\n",
    "        x = self.fc5a(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.dropout5(x)\n",
    "        x = self.fc5b(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7eea22d5-1784-42fb-87e8-b799f1c70125",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = dataset_row.metadata.target.nunique()\n",
    "\n",
    "model1 = BCN20DNN(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e6128b-4101-48cb-bff6-878c4f26ed5f",
   "metadata": {},
   "source": [
    "### Define Training Loop\n",
    "\n",
    "The model uses cross entropy for loss function and Adam optimizer for updating parameter weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ac6e636-244c-4923-a61d-041cfa346f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35d60c3d-a692-4305-8cb0-614203fd63fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, train_loader, val_loader, loss_function, optimizer, num_epochs, device):\n",
    "    \"\"\"\n",
    "    Trains and validates neural network model. \n",
    "\n",
    "    Args:\n",
    "        model: A neural network model object.\n",
    "        train_loader: DataLoader for a training dataset.\n",
    "        val_loader: DataLoader for the validation dataset.\n",
    "        loss_function (callable): The loss function used during training.\n",
    "        optimizer: The optimizer algorithm used to udpate parameter weights. \n",
    "        num_epochs (int): Number of epochs to train the model.\n",
    "        device (torch.devie object): The device to run the training on. \n",
    "        \n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    print(\"------------Training-------------\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for idx, (images, labels) in enumerate(train_loader):\n",
    "            print(idx, end=\"\\r\")\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                val_loss = loss_function(outputs, labels)\n",
    "                running_val_loss += loss.item() * images.size(0)\n",
    "                _, predicted_indices = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted_indices.eq(labels).sum().item()\n",
    "\n",
    "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "\n",
    "        epoch_accuracy = 100.0 * correct / total\n",
    "        val_accuracies.append(epoch_accuracy)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Val Loss: {epoch_val_loss:.4f}, Val Accuracy: {epoch_accuracy:.2f}%\")\n",
    "    print(\"--------Finished Training---------\")\n",
    "\n",
    "    metrics = [train_losses, val_losses, val_accuracies]\n",
    "    \n",
    "    # Return the trained model and the collected metrics\n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b257aa02-2f69-4c28-b575-e9147595f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For imbalanced data, if weighted sampling is used.\n",
    "if use_weighted_samples:\n",
    "    class_counts = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0,}\n",
    "    for i in range(len(train_dataset)):\n",
    "        d, c = train_dataset[i]\n",
    "        class_counts[c] += 1\n",
    "        if i%100 == 0:\n",
    "            print(i, end=\"\\r\")\n",
    "\n",
    "    class_weights = [1.0/class_counts[i] for i in range(8)]\n",
    "    print(class_weights)\n",
    "\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights = class_weights,\n",
    "        num_samples = len(train_dataset),\n",
    "        replacement = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a79755-aa6b-47cf-81bd-0cd9712a169f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fb860af-07d3-4719-a62f-f05e962a937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# if sampler is used for weighted sampling, turn shuffle off. \n",
    "if use_weighted_samples:\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, shuffle=False)\n",
    "else:\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99f064fd-31d4-4366-a35b-eb30e3add1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a092e4-6fec-4601-94e1-54e2ea2f1849",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2046c7e9-a42c-4bd0-a527-3d4048eca95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Training-------------\n",
      "Epoch [1/10], Train Loss: 1.5343, Val Loss: 1.0038, Val Accuracy: 48.90%\n",
      "Epoch [2/10], Train Loss: 1.3911, Val Loss: 1.2191, Val Accuracy: 51.37%\n",
      "Epoch [3/10], Train Loss: 1.3422, Val Loss: 1.1807, Val Accuracy: 53.84%\n",
      "Epoch [4/10], Train Loss: 1.3046, Val Loss: 1.5320, Val Accuracy: 53.41%\n",
      "Epoch [5/10], Train Loss: 1.2752, Val Loss: 1.3389, Val Accuracy: 55.40%\n",
      "Epoch [6/10], Train Loss: 1.2500, Val Loss: 1.2916, Val Accuracy: 56.37%\n",
      "Epoch [7/10], Train Loss: 1.2304, Val Loss: 1.3767, Val Accuracy: 55.94%\n",
      "Epoch [8/10], Train Loss: 1.1978, Val Loss: 1.2568, Val Accuracy: 56.80%\n",
      "Epoch [9/10], Train Loss: 1.1786, Val Loss: 1.2032, Val Accuracy: 57.23%\n",
      "Epoch [10/10], Train Loss: 1.1359, Val Loss: 0.9973, Val Accuracy: 57.71%\n",
      "--------Finished Training---------\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "model1, metrics = training_loop(\n",
    "    model1, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader, \n",
    "    loss_function=loss_function,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=10,\n",
    "    device=adevice,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "726135ec-2b9e-4b2e-93b8-622c4a0b2df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Training-------------\n",
      "Epoch [1/10], Train Loss: 1.1107, Val Loss: 1.0818, Val Accuracy: 56.90%\n",
      "Epoch [2/10], Train Loss: 1.0772, Val Loss: 1.3663, Val Accuracy: 58.52%\n",
      "Epoch [3/10], Train Loss: 1.0423, Val Loss: 1.3133, Val Accuracy: 57.87%\n",
      "Epoch [4/10], Train Loss: 1.0064, Val Loss: 1.0384, Val Accuracy: 58.09%\n",
      "Epoch [5/10], Train Loss: 0.9533, Val Loss: 0.8225, Val Accuracy: 58.09%\n",
      "Epoch [6/10], Train Loss: 0.9237, Val Loss: 0.7291, Val Accuracy: 58.57%\n",
      "Epoch [7/10], Train Loss: 0.8805, Val Loss: 0.8117, Val Accuracy: 58.73%\n",
      "Epoch [8/10], Train Loss: 0.8177, Val Loss: 0.7525, Val Accuracy: 58.09%\n",
      "Epoch [9/10], Train Loss: 0.7769, Val Loss: 0.6568, Val Accuracy: 58.89%\n",
      "Epoch [10/10], Train Loss: 0.7422, Val Loss: 0.6323, Val Accuracy: 60.18%\n",
      "--------Finished Training---------\n"
     ]
    }
   ],
   "source": [
    "model1, metrics = training_loop(\n",
    "    model1, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader, \n",
    "    loss_function=loss_function,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=10,\n",
    "    device=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed1a0253-5c28-416f-a2e9-0508ed51c05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Training-------------\n",
      "Epoch [1/10], Train Loss: 0.6887, Val Loss: 0.7093, Val Accuracy: 59.11%\n",
      "Epoch [2/10], Train Loss: 0.6573, Val Loss: 0.7041, Val Accuracy: 60.40%\n",
      "Epoch [3/10], Train Loss: 0.6170, Val Loss: 0.5584, Val Accuracy: 59.32%\n",
      "Epoch [4/10], Train Loss: 0.5837, Val Loss: 0.3299, Val Accuracy: 59.32%\n",
      "Epoch [5/10], Train Loss: 0.5413, Val Loss: 0.5957, Val Accuracy: 59.75%\n",
      "Epoch [6/10], Train Loss: 0.4982, Val Loss: 0.5530, Val Accuracy: 59.91%\n",
      "Epoch [7/10], Train Loss: 0.4854, Val Loss: 0.3427, Val Accuracy: 59.91%\n",
      "Epoch [8/10], Train Loss: 0.4660, Val Loss: 0.4388, Val Accuracy: 60.83%\n",
      "Epoch [9/10], Train Loss: 0.4454, Val Loss: 0.5023, Val Accuracy: 60.51%\n",
      "Epoch [10/10], Train Loss: 0.3971, Val Loss: 0.3617, Val Accuracy: 62.44%\n",
      "--------Finished Training---------\n"
     ]
    }
   ],
   "source": [
    "model1, metrics = training_loop(\n",
    "    model1, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader, \n",
    "    loss_function=loss_function,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=10,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02e8f624-ef4a-4cf1-8378-d6b08c940a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Training-------------\n",
      "Epoch [1/10], Train Loss: 0.3846, Val Loss: 0.3615, Val Accuracy: 61.04%\n",
      "Epoch [2/10], Train Loss: 0.3699, Val Loss: 0.4991, Val Accuracy: 60.83%\n",
      "Epoch [3/10], Train Loss: 0.3286, Val Loss: 0.4042, Val Accuracy: 62.01%\n",
      "Epoch [4/10], Train Loss: 0.3271, Val Loss: 0.3168, Val Accuracy: 61.74%\n",
      "Epoch [5/10], Train Loss: 0.3001, Val Loss: 0.2240, Val Accuracy: 61.26%\n",
      "Epoch [6/10], Train Loss: 0.3180, Val Loss: 0.4316, Val Accuracy: 61.63%\n",
      "Epoch [7/10], Train Loss: 0.2966, Val Loss: 0.2395, Val Accuracy: 61.63%\n",
      "Epoch [8/10], Train Loss: 0.2786, Val Loss: 0.4047, Val Accuracy: 61.58%\n",
      "Epoch [9/10], Train Loss: 0.2673, Val Loss: 0.0972, Val Accuracy: 61.20%\n",
      "Epoch [10/10], Train Loss: 0.2541, Val Loss: 0.1945, Val Accuracy: 60.24%\n",
      "--------Finished Training---------\n"
     ]
    }
   ],
   "source": [
    "model1, metrics = training_loop(\n",
    "    model1, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader, \n",
    "    loss_function=loss_function,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=10,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3827fef-9456-4cb0-9f1d-3f468c6da17a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
