{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8707f966-5b28-4d4f-9c77-65882f59387a",
   "metadata": {},
   "source": [
    "## A ResNet Model to Classify BCN20000 Dataset\n",
    "\n",
    "This is the second model built to classify the BCN20000 dataset. More details about the dataset can be found in the [first notebookðŸ¡µ](https://github.com/ngpraveen/Deep-Learning-models-for-BCN20000-dataset-classification/blob/main/CNN_Model_for_BCN20000_dataset.ipynb).\n",
    "\n",
    "In this notebook, we utilize transfer learning using ResNet-18 model with its default weights. All layers except the last fully connected layer are frozen. \n",
    "\n",
    "\n",
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2f0c90-717e-4aba-8be7-db163aa71744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "330a3123-dad3-488f-8592-e6a1d27a558d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf70df37-6c29-43a1-bdf4-559b58fa68cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/mnt/c/Users/prave/data/bcn20k_figshare/'\n",
    "\n",
    "target_map = {'NV': 0, 'MEL': 1, 'BCC': 2, 'BKL': 3, 'AK': 4, 'SCC': 5, 'DF': 6, 'VASC': 7}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357f2f00-d7d1-447d-a1b9-9b6af6f4d549",
   "metadata": {},
   "source": [
    "### 2. Create a Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3869be3e-958b-4f60-8e24-843eb5c71791",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCNDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Creates a custom dataset class that inherits from PyTorch's Dataset class.\n",
    "    The metadata content (bcn_20k_train.csv) is added to an attribute `metadata`.\n",
    "    The output class is defined in the column `diagnosis` which is coded to 0, 1, 2, ...\n",
    "    as defined in `target_map`.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): The root directory where the dataset is stored. \n",
    "        transform (callable, optional): Optional transform to be applied to the input data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir: str, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_dir = os.path.join(root_dir, \"train\")\n",
    "        self.transform = transform\n",
    "        self.metadata = self.load_metadata()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx:int):\n",
    "        image, label = self.retrieve_image(idx)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)        \n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "    def load_metadata(self):\n",
    "        metadata = pd.read_csv(\n",
    "            os.path.join(self.root_dir, \"bcn_20k_train.csv\")\n",
    "        )\n",
    "        \n",
    "        target_map = {'NV': 0, 'MEL': 1, 'BCC': 2, 'BKL': 3, 'AK': 4, 'SCC': 5, 'DF': 6, 'VASC': 7}\n",
    "        metadata['target'] = metadata['diagnosis'].map(target_map)\n",
    "        return metadata\n",
    "    \n",
    "\n",
    "    def retrieve_image(self, idx: int):\n",
    "        image_name = self.metadata[\"bcn_filename\"].iloc[idx]\n",
    "        image_path = os.path.join(self.image_dir, image_name) \n",
    "        label = self.metadata[\"target\"].iloc[idx]\n",
    "        with Image.open(image_path) as img:\n",
    "            image = img.convert(\"RGB\")\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac1eb5d-e53f-4f3b-9579-b3e44652d910",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_row = BCNDataset(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93572002-35b7-4a8b-81b6-b33cf4fc1aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bcn_filename</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>capture_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>split</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCN_0000000001.jpg</td>\n",
       "      <td>55.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>MEL</td>\n",
       "      <td>BCN_0003884</td>\n",
       "      <td>2012-05-16</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCN_0000000003.jpg</td>\n",
       "      <td>50.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>MEL</td>\n",
       "      <td>BCN_0000019</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>female</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCN_0000000004.jpg</td>\n",
       "      <td>85.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>SCC</td>\n",
       "      <td>BCN_0003499</td>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCN_0000000006.jpg</td>\n",
       "      <td>60.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>NV</td>\n",
       "      <td>BCN_0003316</td>\n",
       "      <td>2015-06-16</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCN_0000000010.jpg</td>\n",
       "      <td>30.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCN_0004874</td>\n",
       "      <td>2014-02-18</td>\n",
       "      <td>female</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12408</th>\n",
       "      <td>BCN_0000020348.jpg</td>\n",
       "      <td>85.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCN_0003925</td>\n",
       "      <td>2013-03-05</td>\n",
       "      <td>female</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12409</th>\n",
       "      <td>BCN_0000020349.jpg</td>\n",
       "      <td>65.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>BKL</td>\n",
       "      <td>BCN_0001819</td>\n",
       "      <td>2016-05-05</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12410</th>\n",
       "      <td>BCN_0000020350.jpg</td>\n",
       "      <td>70.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>MEL</td>\n",
       "      <td>BCN_0001085</td>\n",
       "      <td>2015-01-29</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12411</th>\n",
       "      <td>BCN_0000020352.jpg</td>\n",
       "      <td>55.0</td>\n",
       "      <td>palms/soles</td>\n",
       "      <td>NV</td>\n",
       "      <td>BCN_0002083</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>female</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12412</th>\n",
       "      <td>BCN_0000020355.jpg</td>\n",
       "      <td>50.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>BKL</td>\n",
       "      <td>BCN_0001079</td>\n",
       "      <td>2015-06-25</td>\n",
       "      <td>male</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12413 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             bcn_filename  age_approx anatom_site_general diagnosis  \\\n",
       "0      BCN_0000000001.jpg        55.0      anterior torso       MEL   \n",
       "1      BCN_0000000003.jpg        50.0      anterior torso       MEL   \n",
       "2      BCN_0000000004.jpg        85.0           head/neck       SCC   \n",
       "3      BCN_0000000006.jpg        60.0      anterior torso        NV   \n",
       "4      BCN_0000000010.jpg        30.0      anterior torso       BCC   \n",
       "...                   ...         ...                 ...       ...   \n",
       "12408  BCN_0000020348.jpg        85.0           head/neck       BCC   \n",
       "12409  BCN_0000020349.jpg        65.0      anterior torso       BKL   \n",
       "12410  BCN_0000020350.jpg        70.0     lower extremity       MEL   \n",
       "12411  BCN_0000020352.jpg        55.0         palms/soles        NV   \n",
       "12412  BCN_0000020355.jpg        50.0     upper extremity       BKL   \n",
       "\n",
       "         lesion_id capture_date     sex  split  target  \n",
       "0      BCN_0003884   2012-05-16    male  train       1  \n",
       "1      BCN_0000019   2015-07-09  female  train       1  \n",
       "2      BCN_0003499   2015-11-23    male  train       5  \n",
       "3      BCN_0003316   2015-06-16    male  train       0  \n",
       "4      BCN_0004874   2014-02-18  female  train       2  \n",
       "...            ...          ...     ...    ...     ...  \n",
       "12408  BCN_0003925   2013-03-05  female  train       2  \n",
       "12409  BCN_0001819   2016-05-05    male  train       3  \n",
       "12410  BCN_0001085   2015-01-29    male  train       1  \n",
       "12411  BCN_0002083   2016-05-08  female  train       0  \n",
       "12412  BCN_0001079   2015-06-25    male  train       3  \n",
       "\n",
       "[12413 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_row.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50798a45-785e-4253-a630-dbbc6641f81a",
   "metadata": {},
   "source": [
    "### 3. Split Dataset and Create a Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7451a4-4096-48fa-8a6b-38cff1732ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, val_fraction=0.15, test_fraction=0.15):\n",
    "    \"\"\"\n",
    "    Randomly split dataset into train, validation and test datasets.\n",
    "    By default, splits in to 70%, 15% and 15%. \n",
    "\n",
    "    Args:\n",
    "        dataset: The dataset object which is split into train, validation and test datasets.\n",
    "        val_fraction (float, optional): Fraction of the dataset to be included in the validation set.\n",
    "        test_fraction (float, optional): Fraction of the dataset to be included in the test set.  \n",
    "    \"\"\"\n",
    "    \n",
    "    total_size = len(dataset)\n",
    "    val_size = int(total_size * val_fraction)\n",
    "    test_size = int(total_size * test_fraction)\n",
    "    train_size = total_size - val_size - test_size\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, \n",
    "                                                            [train_size, val_size, test_size])\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8012f662-d3ce-42d3-8df3-e261f6a5f924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10552, 1861, 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset1, val_dataset1, test_dataset1 = split_dataset(dataset_row, 0.15, 0.0)\n",
    "len(train_dataset1), len(val_dataset1), len(test_dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08c55fb2-06c4-434e-95de-3d4b2f1922c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubsetWithTransform(Dataset):\n",
    "    \"\"\"\n",
    "    Creates a subset class from BCNDataset objects. \n",
    "    Helps with applying different transforms to the train, validation \n",
    "    and test datasets. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, subset, transform=None):\n",
    "        print(subset)\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.subset[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5621e367-5aa9-4bb5-8477-9b14425a9e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define different transforms for train and validation+test sets. \n",
    "# Train dataset is augmented with horizontal flip, random rotation etc. \n",
    "# But validation and test sets are not augmented. \n",
    "mean, std = [0.6125, 0.5277, 0.5061], [0.4241, 0.3242, 0.3054]\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2),\n",
    "    transforms.Resize((256, 256)),  # Resize images to 256x256 pixels\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# for validation and test sets.\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize images to 256x256 pixels\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50f381d2-2707-464a-bc07-fc96fa00247a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.Subset object at 0x7f939dd02350>\n",
      "<torch.utils.data.dataset.Subset object at 0x7f939dd021d0>\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SubsetWithTransform(train_dataset1, transform=train_transform)\n",
    "val_dataset = SubsetWithTransform(val_dataset1, transform=val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaf20b1-a5f3-45a5-be0b-17b08b5bb8dd",
   "metadata": {},
   "source": [
    "### 4. Import ResNet Model\n",
    "\n",
    "The pretrained ResNet-18 model is imported and all layers are frozen except the last fully connected layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b21ea74-fbe1-4608-88e0-7249d2597756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/prave/venvs/bcn20k/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/prave/venvs/bcn20k/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18dfd6ea-bd3b-4260-9425-a5b619d0d7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the number of input features for the fully connected layers\n",
    "fc_in_features_count = model.fc.in_features\n",
    "fc_in_features_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe5ac943-ffdd-438e-911c-36821345ee74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Redesigning the fully connected layer so that the number of outputs matches the number of classes.\n",
    "num_classes = dataset_row.metadata.target.nunique()\n",
    "print(num_classes)\n",
    "model.fc = nn.Linear(fc_in_features_count, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb1b3c4-b51f-4fee-a97d-4d9b2c781796",
   "metadata": {},
   "source": [
    "### 5. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71fbad91-407f-49d2-998f-e16b96e87bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55eebbe6-ec37-4ca7-bca3-cef48d6c3a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f926484d010>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c450362-d40c-4ed3-91ca-335b9a6fd5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=64, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2436163-566e-4d38-b867-bdb9243b0dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "---\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# freeze all layers except the fully connected layer\n",
    "ct = 0\n",
    "\n",
    "for child in model.children():\n",
    "    ct += 1\n",
    "    print(ct)\n",
    "    if ct < 10:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "print(\"---\")\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66cd67c9-1a23-4ce2-849a-f6e46243cf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "Training...\n",
      "  Loss: 0.021 Acc: 51.857 Time: 648.7401292324066\n",
      "  Val Loss: 0.020 Acc: 56.905 Time: 790.1569657325745\n",
      "\n",
      "Epoch 1:\n",
      "Training...\n",
      "  Loss: 0.018 Acc: 58.908 Time: 620.8193662166595\n",
      "  Val Loss: 0.019 Acc: 57.227 Time: 739.585294008255\n",
      "\n",
      "Epoch 2:\n",
      "Training...\n",
      "  Loss: 0.017 Acc: 59.647 Time: 613.6119961738586\n",
      "  Val Loss: 0.019 Acc: 57.603 Time: 726.1651830673218\n",
      "\n",
      "Epoch 3:\n",
      "Training...\n",
      "  Loss: 0.017 Acc: 60.358 Time: 606.1249845027924\n",
      "  Val Loss: 0.018 Acc: 59.807 Time: 715.8717143535614\n",
      "\n",
      "Epoch 4:\n",
      "Training...\n",
      "  Loss: 0.017 Acc: 60.624 Time: 601.303985118866\n",
      "  Val Loss: 0.018 Acc: 60.290 Time: 709.8070316314697\n",
      "\n",
      "Epoch 5:\n",
      "Training...\n",
      "  Loss: 0.017 Acc: 61.041 Time: 600.4843907356262\n",
      "  Val Loss: 0.018 Acc: 58.571 Time: 709.4336223602295\n",
      "\n",
      "Epoch 6:\n",
      "Training...\n",
      "  Loss: 0.017 Acc: 61.458 Time: 600.9018428325653\n",
      "  Val Loss: 0.018 Acc: 60.021 Time: 709.6395988464355\n",
      "\n",
      "Epoch 7:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 61.410 Time: 607.8289475440979\n",
      "  Val Loss: 0.018 Acc: 60.559 Time: 716.5111970901489\n",
      "\n",
      "Epoch 8:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 62.045 Time: 599.2770023345947\n",
      "  Val Loss: 0.018 Acc: 59.968 Time: 708.120233297348\n",
      "\n",
      "Epoch 9:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 62.036 Time: 603.2664878368378\n",
      "  Val Loss: 0.018 Acc: 60.451 Time: 712.121907711029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "train_accuracy = []\n",
    "val_loss = []\n",
    "val_accuracy = []\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Epoch {epoch}:\")\n",
    "    print(\"Training...\")\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct_counts = 0\n",
    "\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        print(f\"[{i} / {len(train_loader)}]\", end=\"\\r\")\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        running_correct_counts += preds.eq(targets).sum().item()\n",
    "\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_correct_counts / len(train_dataset) * 100.0\n",
    "    train_loss.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_acc)\n",
    "    print(f\"  Loss: {epoch_loss:.3f} Acc: {epoch_acc:.3f} Time: {time.time()-start_time}\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        running_correct_counts = 0\n",
    "\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, outputs = inputs.to(device), outputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            running_loss += loss.item()\n",
    "            running_correct_counts += preds.eq(targets).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(val_dataset)\n",
    "        epoch_acc = running_correct_counts / len(val_dataset) * 100.0\n",
    "\n",
    "        val_loss.append(epoch_loss)\n",
    "        val_accuracy.append(epoch_acc)\n",
    "\n",
    "        print(f\"  Val Loss: {epoch_loss:.3f} Acc: {epoch_acc:.3f} Time: {time.time()-start_time}\")\n",
    "        print(\"\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a2c266-3ed7-4045-8512-29626c5fbb89",
   "metadata": {},
   "source": [
    "#### 5.1 Repeat another 40 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a641ba20-98d7-486f-b239-36c12aa3f9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 61.296 Time: 603.9469404220581\n",
      "  Val Loss: 0.018 Acc: 60.183 Time: 711.6400022506714\n",
      "\n",
      "Epoch 1:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 61.960 Time: 599.7438161373138\n",
      "  Val Loss: 0.018 Acc: 60.613 Time: 708.285281419754\n",
      "\n",
      "Epoch 2:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 62.292 Time: 625.2070240974426\n",
      "  Val Loss: 0.017 Acc: 61.042 Time: 734.9142837524414\n",
      "\n",
      "Epoch 3:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 62.424 Time: 602.7308971881866\n",
      "  Val Loss: 0.018 Acc: 60.129 Time: 710.8291759490967\n",
      "\n",
      "Epoch 4:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 62.007 Time: 597.9945247173309\n",
      "  Val Loss: 0.018 Acc: 60.559 Time: 706.3828616142273\n",
      "\n",
      "Epoch 5:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 62.055 Time: 599.4905428886414\n",
      "  Val Loss: 0.018 Acc: 60.828 Time: 707.587085723877\n",
      "\n",
      "Epoch 6:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 62.945 Time: 598.2860956192017\n",
      "  Val Loss: 0.018 Acc: 60.935 Time: 707.0263533592224\n",
      "\n",
      "Epoch 7:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 62.301 Time: 596.8837099075317\n",
      "  Val Loss: 0.018 Acc: 58.517 Time: 705.4372708797455\n",
      "\n",
      "Epoch 8:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 62.756 Time: 597.8391933441162\n",
      "  Val Loss: 0.018 Acc: 61.580 Time: 706.3268735408783\n",
      "\n",
      "Epoch 9:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 62.926 Time: 599.3004169464111\n",
      "  Val Loss: 0.017 Acc: 61.042 Time: 707.6706552505493\n",
      "\n",
      "Epoch 10:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 63.021 Time: 599.0158250331879\n",
      "  Val Loss: 0.019 Acc: 58.302 Time: 707.4655380249023\n",
      "\n",
      "Epoch 11:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 63.192 Time: 602.0070612430573\n",
      "  Val Loss: 0.018 Acc: 61.042 Time: 710.4785003662109\n",
      "\n",
      "Epoch 12:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 62.756 Time: 599.3003177642822\n",
      "  Val Loss: 0.017 Acc: 61.956 Time: 707.957861661911\n",
      "\n",
      "Epoch 13:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 63.249 Time: 598.9233367443085\n",
      "  Val Loss: 0.018 Acc: 61.526 Time: 707.4345626831055\n",
      "\n",
      "Epoch 14:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 63.059 Time: 598.5588610172272\n",
      "  Val Loss: 0.018 Acc: 60.451 Time: 707.1849312782288\n",
      "\n",
      "Epoch 15:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 63.173 Time: 599.482045173645\n",
      "  Val Loss: 0.018 Acc: 60.290 Time: 708.1362714767456\n",
      "\n",
      "Epoch 16:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 63.258 Time: 598.9569203853607\n",
      "  Val Loss: 0.017 Acc: 61.204 Time: 707.1263191699982\n",
      "\n",
      "Epoch 17:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 63.125 Time: 598.8293297290802\n",
      "  Val Loss: 0.017 Acc: 61.902 Time: 706.9614169597626\n",
      "\n",
      "Epoch 18:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 62.784 Time: 599.214323759079\n",
      "  Val Loss: 0.018 Acc: 60.398 Time: 707.8692927360535\n",
      "\n",
      "Epoch 19:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 63.144 Time: 597.737676858902\n",
      "  Val Loss: 0.017 Acc: 61.902 Time: 706.2651472091675\n",
      "\n",
      "Epoch 20:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 63.419 Time: 598.0638220310211\n",
      "  Val Loss: 0.018 Acc: 61.042 Time: 706.7357649803162\n",
      "\n",
      "Epoch 21:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 63.647 Time: 604.1451950073242\n",
      "  Val Loss: 0.017 Acc: 62.117 Time: 712.4118146896362\n",
      "\n",
      "Epoch 22:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 63.561 Time: 597.5973496437073\n",
      "  Val Loss: 0.018 Acc: 61.257 Time: 706.1752007007599\n",
      "\n",
      "Epoch 23:\n",
      "Training...\n",
      "  Loss: 0.016 Acc: 63.040 Time: 599.1158454418182\n",
      "  Val Loss: 0.017 Acc: 61.419 Time: 707.9665756225586\n",
      "\n",
      "Epoch 24:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 63.495 Time: 597.296701669693\n",
      "  Val Loss: 0.017 Acc: 61.365 Time: 705.7650716304779\n",
      "\n",
      "Epoch 25:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 63.779 Time: 598.538583278656\n",
      "  Val Loss: 0.018 Acc: 59.269 Time: 706.9444527626038\n",
      "\n",
      "Epoch 26:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 63.078 Time: 598.3377184867859\n",
      "  Val Loss: 0.017 Acc: 60.881 Time: 706.6077389717102\n",
      "\n",
      "Epoch 27:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 63.400 Time: 597.8443315029144\n",
      "  Val Loss: 0.018 Acc: 61.419 Time: 706.4402508735657\n",
      "\n",
      "Epoch 28:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 63.192 Time: 598.0274217128754\n",
      "  Val Loss: 0.017 Acc: 61.150 Time: 706.8320000171661\n",
      "\n",
      "Epoch 29:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 63.779 Time: 598.1027679443359\n",
      "  Val Loss: 0.018 Acc: 60.666 Time: 706.8203942775726\n",
      "\n",
      "Epoch 30:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 63.353 Time: 598.7685487270355\n",
      "  Val Loss: 0.017 Acc: 60.666 Time: 707.1175055503845\n",
      "\n",
      "Epoch 31:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 63.448 Time: 598.9134089946747\n",
      "  Val Loss: 0.018 Acc: 60.290 Time: 707.7761933803558\n",
      "\n",
      "Epoch 32:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 63.561 Time: 599.1701023578644\n",
      "  Val Loss: 0.018 Acc: 61.365 Time: 707.5532898902893\n",
      "\n",
      "Epoch 33:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 63.173 Time: 600.6932544708252\n",
      "  Val Loss: 0.017 Acc: 61.419 Time: 709.2889988422394\n",
      "\n",
      "Epoch 34:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 63.296 Time: 598.086704492569\n",
      "  Val Loss: 0.017 Acc: 61.096 Time: 706.735897064209\n",
      "\n",
      "Epoch 35:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 64.092 Time: 598.8584547042847\n",
      "  Val Loss: 0.018 Acc: 61.472 Time: 707.7009115219116\n",
      "\n",
      "Epoch 36:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 63.694 Time: 597.9158453941345\n",
      "  Val Loss: 0.018 Acc: 61.687 Time: 706.2119786739349\n",
      "\n",
      "Epoch 37:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 63.789 Time: 599.8535478115082\n",
      "  Val Loss: 0.018 Acc: 60.720 Time: 708.333822965622\n",
      "\n",
      "Epoch 38:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 62.860 Time: 598.6433255672455\n",
      "  Val Loss: 0.017 Acc: 60.398 Time: 707.0482566356659\n",
      "\n",
      "Epoch 39:\n",
      "Training...\n",
      "  Loss: 0.015 Acc: 63.865 Time: 602.1841297149658\n",
      "  Val Loss: 0.017 Acc: 61.580 Time: 710.7253413200378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "train_accuracy = []\n",
    "val_loss = []\n",
    "val_accuracy = []\n",
    "\n",
    "epochs = 40\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Epoch {epoch}:\")\n",
    "    print(\"Training...\")\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct_counts = 0\n",
    "\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        print(f\"[{i} / {len(train_loader)}]\", end=\"\\r\")\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        running_correct_counts += preds.eq(targets).sum().item()\n",
    "\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_correct_counts / len(train_dataset) * 100.0\n",
    "    train_loss.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_acc)\n",
    "    print(f\"  Loss: {epoch_loss:.3f} Acc: {epoch_acc:.3f} Time: {time.time()-start_time}\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        running_correct_counts = 0\n",
    "\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, outputs = inputs.to(device), outputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            running_loss += loss.item()\n",
    "            running_correct_counts += preds.eq(targets).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(val_dataset)\n",
    "        epoch_acc = running_correct_counts / len(val_dataset) * 100.0\n",
    "\n",
    "        val_loss.append(epoch_loss)\n",
    "        val_accuracy.append(epoch_acc)\n",
    "\n",
    "        print(f\"  Val Loss: {epoch_loss:.3f} Acc: {epoch_acc:.3f} Time: {time.time()-start_time}\")\n",
    "        print(\"\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ecdc70-6390-4a67-8ade-f0b2dff860b7",
   "metadata": {},
   "source": [
    "### 6. Conclusion\n",
    "\n",
    "We employed transfer learning using ResNet-18 model, keeping all layers except the final fully connected layer frozen. The performance of the model is comparable with the custom CNN model trained in a separate notebook. However, it is to be noted that this dataset is imbalanced. I will examine the effectiveness of sampling methods, hierarchical classification etc.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
